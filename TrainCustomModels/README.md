# Entrenar detectores personalizados (YOLOv4)

Esta carpeta ofrece un **pipeline completo** para preparar datasets en formato COCO/Roboflow, convertirlos a tablas MATLAB, **entrenar YOLOv4** (incluida la variante *tiny*), evaluar y probar el detector tanto en imÃ¡genes como **en vivo con webcam**.

---

## ğŸ“‚ Estructura

```text
TrainCustomModels/
â”œâ”€â”€ coco2table.m                 # COCO/Roboflow JSON â†’ tabla MATLAB (bbox + clases)
â”œâ”€â”€ convertDataset.m             # Orquesta la conversiÃ³n por splits (train/valid/test)
â”œâ”€â”€ formatForYOLO.m              # Adapter de muestras para datastores combinados
â”œâ”€â”€ preprocessDataYOLOv4.m       # (Opcional) Resize/augment para flujo alternativo
â”œâ”€â”€ runYOLOv4.m                  # Script de experiencia: entrena y prueba
â”œâ”€â”€ trainBoxesYOLOv4.m           # Entrenamiento/validaciÃ³n/evaluaciÃ³n (nÃºcleo)
â”œâ”€â”€ webcamPredict.m              # Inferencia en vivo con webcam
â””â”€â”€ (salidas) checkpoints/, trainedDetectorYOLOv4.mat, curvas Pâ€“R, etc.
```

---

## ğŸ§ª Flujo recomendado

1) **Convierte** tu dataset COCO (JSON) a tablas: `convertDataset.m`  
2) **Entrena** con `runYOLOv4.m` (llama internamente a `trainBoxesYOLOv4`).  
3) **Valida/visualiza** mÃ©tricas y guarda `trainedDetectorYOLOv4.mat`.  
4) **Prueba** detecciÃ³n en imÃ¡genes o **en vivo** con `webcamPredict.m`.

---

## ğŸ“Œ Scripts y funciones

### `coco2table.m` â€” COCO JSON â†’ tabla MATLAB
**QuÃ© hace:** parsea el JSON COCO de Roboflow y construye una **tabla** con:
- `imageFilename` (`string`): ruta absoluta de cada imagen  
- `objectBoundingBoxes` (`cell{MÃ—4 double}`): `[x y w h]`  
- `objectClass` (`cell{MÃ—1 categorical}`)

Omite imÃ¡genes sin cajas y normaliza cada bbox a 1Ã—4. **Salida consistente** para entrenamiento.

**Entradas**
- `jsonFile`: ruta al `_annotations.coco.json`  
- `imgFolder`: carpeta de imÃ¡genes

**Salida**
- `tbl` (`table`): rutas, bboxes y etiquetas

---

### `convertDataset.m` â€” ConversiÃ³n por *splits*
**QuÃ© hace:** recorre `train/valid/test`, valida el `_annotations.coco.json` y las imÃ¡genes, llama a `coco2table` y **guarda** en cada carpeta un `.mat` con `tbl` (ej.: `train_cocoTable.mat`).

**Entradas**
- Usa `pwd` como raÃ­z; espera `datasets/<proyecto>/{train,valid,test}`  
- Nombres estÃ¡ndar: `_annotations.coco.json` + imÃ¡genes

**Salidas**
- En cada split: `<split>_cocoTable.mat` con la variable `tbl`

---

### `formatForYOLO.m` â€” *Adapter* para datastores
**QuÃ© hace:** estandariza a `{I, boxes, labels}` para flujos con `combine(imageDatastore, boxLabelDatastore)`:
- Si la entrada ya es `{I, boxes, labels}`, la deja igual  
- Si es `{I, tbl}` (o `{I, {tbl}}`), **extrae** `objectBoundingBoxes` y `objectClass`

**Entrada**: `dataIn` = `{I, boxes, labels}` **o** `{I, tbl}` / `{I, {tbl}}`  
**Salida**: `dataOut` = `{I, boxes, labels}`

---

### `preprocessDataYOLOv4.m` â€” (Opcional) Resize/augment
**QuÃ© hace:** ejemplo de *preprocess* sencillo (no usado por defecto). Hace `imresize` a un `target` (p. ej., 416Ã—416), ajusta cajas con el *scale* correspondiente y devuelve `{I_resized, bboxes_rescaled}`. Ãštil para experimentar con pipeline manual.

**Entradas**: `in = {I, b}`, `target = [H W C]`  
**Salida**: `out = {I_resized, b_resized}`

---

### `trainBoxesYOLOv4.m` â€” Entrenar y evaluar (nÃºcleo)
**Pasos principales:**
1. **Carga/limpieza** de tablas `train/valid/test`; elimina categorÃ­as vacÃ­as  
2. **Clip/Drop** de cajas fuera del encuadre real de cada imagen  
3. **Datastores combinados** y `formatForYOLO` â†’ `{I, boxes, labels}`  
4. **EstimaciÃ³n de anchors**: 9 por defecto; para *tiny* usa 6 y los divide 3+3  
5. **Detector base** con **InputSize** `[416 416 3]` por defecto  
6. **Entrenamiento** y **checkpoints**  
7. **EvaluaciÃ³n**: curvas Pâ€“R, mÃ©tricas (incluye *mAP@0.5*, *precision*, *recall*) y figuras

**Entradas**
- `dataDir`: raÃ­z con `train/valid/test` (cada split con su `*_cocoTable.mat` + imÃ¡genes)  
- `checkpointsFolder`: carpeta para *snapshots*  
- `modelName`: `"csp-darknet53-coco"` o `"tiny-yolov4-coco"`

**Salidas**
- `detector`: `yolov4ObjectDetector` listo para `detect(...)`  
- Carpeta `checkpoints/` y mÃ©tricas/figuras generadas

**Notas**
- *Anchors*: ordenados por Ã¡rea y divididos en grupos (2 si *tiny*, 3 si estÃ¡ndar)  
- *InputSize*: el *resize* se maneja en el *reader*

---

### `runYOLOv4.m` â€” Experimento de punta a punta
**QuÃ© hace:** define carpetas y `modelName`, **llama** a `trainBoxesYOLOv4` y **predice** sobre una imagen de *test*, dibujando cajas + *scores* (ejemplo mÃ­nimo de *inference-after-train*).

**Entradas**: variables internas (`datasetFolder`, `projectName`, `modelName`)  
**Salidas**: variable `detector` en el *workspace* y figura con detecciones

---

### `webcamPredict.m` â€” *Live demo* con webcam
**QuÃ© hace:** carga `trainedDetectorYOLOv4.mat` (variable `detector`), abre la webcam (Support Package), **detecta en vivo** y dibuja `label: score` en cada cuadro. Muestra FPS y permite bajar resoluciÃ³n para ganar rendimiento.

**Entrada**: `trainedDetectorYOLOv4.mat` en la misma carpeta  
**Salida**: ventana con *preview* y detecciones en tiempo real (FPS en tÃ­tulo)

---

## ğŸ§© Piezas relacionadas (detecciÃ³n e inferencia)

- **`myDetector.m`**: detector **CPU**; garantiza RGB y llama a `detect(det,I,Threshold=...)`.  
  **Salidas**: `[bboxes, scores, labels]` (labels como *cellstr*).

- **`myDetectorGPU.m`**: detector **GPU/Codegen** con firma  
  `[b,s,lIdx] = myDetectorGPU(im, detectorFile, threshold)`; carga el detector una vez, asegura 3 canales y devuelve **Ã­ndices** de clase (1-based).

- **`myDetectorGPU_generation_script.m`**: prepara **codegen** para Jetson (dll + *Embedded Coder*), fija `inputSize` desde el detector, define tipos y genera `myDetectorGPU.so`.

- **`testDetector.m`**: *harness* para comparar CPU/GPU y **normalizar etiquetas** a texto antes de dibujar anotaciones.

> Para despliegue en ROS (fuera de esta carpeta), los nodos C++ publican:  
> â€¢ `/network_view` (imagen RGB recortada)  
> â€¢ `/network_detections` (Float32MultiArray con filas `[x y w h score labelIdx]`)  
> VisualÃ­zalo desde MATLAB con `visualizeROSDetector.m`.

---

## â–¶ï¸ Ejemplos rÃ¡pidos

### Entrenar (fin a fin) y probar una imagen
```matlab
% 1) AsegÃºrate de tener datasets/<proyecto>/{train,valid,test}
convertDataset        % crea train_cocoTable.mat, etc.

% 2) Lanza experimento
runYOLOv4             % entrena y prueba sobre una imagen de test
```

### Cargar detector y detectar en vivo (webcam)
```matlab
% tras el entrenamiento, asegÃºrate de tener trainedDetectorYOLOv4.mat
webcamPredict
```

---

## ğŸ“¦ Salidas tÃ­picas

- `trainedDetectorYOLOv4.mat` (variable `detector` lista para `detect(...)`)  
- Carpeta `checkpoints/<proyecto>/` con snapshots y logs de entrenamiento  
- Figuras/curvas de evaluaciÃ³n (Pâ€“R, *mean IoU* de anchors, etc.)  
- `*_cocoTable.mat` en cada split (train/valid/test)

---

## ğŸ’¡ Consejos prÃ¡cticos

- **Calidad de anotaciones**: el *clip/drop* ya estÃ¡ incluido para evitar cajas fuera de imagen y obtener *anchors* mÃ¡s estables.  
- **Anchors y tamaÃ±o**: usa 416Ã—416Ã—3 como base; si cambias la resoluciÃ³n, re-estima anchors tras el *resize* esperado.  
- **`formatForYOLO`** simplifica las combinaciones `{I, tbl}` â†’ `{I, boxes, labels}` en *mini-batches*.  
- **Webcam**: baja la resoluciÃ³n si tu cÃ¡mara es 1080p/4K para ganar FPS.  
- **Tiny vs. full**: *tiny-yolov4-coco* usa 6 anchors (dos grupos de 3) y es mÃ¡s ligero; el modelo completo usa 9 anchors (tres grupos).

---

## ğŸ§¯ Problemas comunes y soluciones (breve)

- **â€œNo encuentra el JSONâ€**  
  Verifica la estructura `datasets/<proyecto>/{train,valid,test}` y el nombre **`_annotations.coco.json`** en cada split. Ejecuta `convertDataset.m` desde la raÃ­z del proyecto y comprueba rutas absolutas en `imageFilename`.

- **â€œAnchors raros / resultados inestablesâ€**  
  AsegÃºrate de que las cajas se estimen al **tamaÃ±o de entrada efectivo** (por defecto 416Ã—416). El pipeline ya hace *clip/drop*; si cambias `InputSize`, **re-estima anchors**. Para *tiny*, usa 6 anchors y divisiÃ³n 3+3.

- **â€œOut of memory (entrenamiento)â€**  
  Reduce el **mini-batch**, usa la variante **`tiny-yolov4-coco`**, y/o disminuye la resoluciÃ³n de entrada coherentemente con una nueva estimaciÃ³n de anchors. MantÃ©n activados los **checkpoints** para reanudar.

- **â€œLa webcam no abre o va muy lentaâ€**  
  Instala el **Support Package** de webcams, baja la **resoluciÃ³n** en `webcamPredict.m` y ajusta el `Threshold` si hace falta. 

- **â€œDibuja mal las cajas / imagen en B/Nâ€**  
  Usa los *wrappers* (`myDetector.m` / `myDetectorGPU.m`) que garantizan **RGB** y formateo de salida `[bboxes, scores, labels]` (o Ã­ndices en GPU).

---